---
title: "USSP25 JPI"
author: "Gabriel Bowen"
date: "2025-07-31"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(2012)
```

## Introduction

The goals of this workshop are:

1. To demonstrate that Bayesian proxy inversion (what we called **Joint Proxy Inversion** in our 2020 paper on the topic) isn't so difficult and can be done with your data,
2. To give you a glimpse 'under the hood' of MCMC, and,
3. To let you experiment with some of the assumptions and details involved.

The materials are written to be accessible at a range of different experience levels, and the goals are cumulative. Don't be disappointed if you don't get to the very end, or even if you feel like you don't get much past goal #1. You can always come back and review or continue working later.

We will be working with a 2-proxy system: Mg/Ca and $\delta^{18}$O of planktonic foraminifera (genus *Morozovella*), The data come from [Zachos et al., 2003](https://doi.org/10.1126/science.1090110), and are from ODP Site 1209 in the tropical Pacific. We will run some simple inversions, starting with a single sample, to reconstruct sea surface temperature (SST) and sea water $\delta^{18}$O values.

## Getting started

Grey blocks contain R code that can be copy-pasted (or retyped) on your computer. I recommend composing your code in two "script" windows, one which contains your functions and another which contains the code you use to run them. 

If you're new to coding, a function is a chunk of code that takes input and produces output. For example:

```{r initial}
#initialize the chain
init = function(){
  sst = runif(1, 15, 35)
  d18O.sw = rnorm(1, 0.5, 0.5)
  mgca.b = rnorm(1, 0.4, 0.02)
  mgca.m = rnorm(1, 0.096, 0.004)
  d18O.b = rnorm(1, 2.9, 0.1)
  d18O.m = rnorm(1, 0.213, 0.005)
  
  return(list("sst" = sst, "d18O.sw" = d18O.sw,
              "mgca.b" = mgca.b, "mgca.m" = mgca.m,
              "d18O.b" = d18O.b, "d18O.m" = d18O.m))
}
```

If you are familiar with R or a similar language you might be able to break down and understand the syntax here...we don't have time to give a full programming course today, however, so we will focus on the scientific 'meaning' of the code rather than the details of how it's written.

This function creates a set of 6 values (`sst`, `d18O.sw`, etc.). Each is generated by drawing a random value from a statistical distribution, either a normal (Gaussian, `rnorm`) or uniform (`runif`) distribution. The parameters of the distribution are given in parentheses (the first value says that we only will draw one value, the second and third paramters are either mean and sd or min and max). The function finishes by returning the values it created.

To 'create' the function we need to enter the code into R and then **compile** it by running the first line. Go ahead and do that now. Once we've done that, we can **call** the function like so:

```{r runInit}
parm = init()
parm
```

Your values will look different than mine...remember we're picking random values from the distributions. 

What is this good for? We are going to use MCMC to generate a posterior distribution of environmental values based on our proxy data. Markov chains are state-dependent, meaning they need a starting point. We have just generated a starting point for the 6 parameters that will be used in our model:

- SST (`sst`),
- Seawater $\delta^{18}$O (`d18O.sw`),
- The exponential (`mgca.m`) and pre-exponential (`mgca.b`) terms in the transfer function describing the effect of SST on foraminiferal Mg/Ca, and,
- The slope and intercept of the transfer function describing the effect of temperature and seawater $\delta^{18}$O on foraminiferal $\delta^{18}$O.

These distributions will serve as the **priors** on our six model parameters. Where did they come from? 

- SST: I used a broad uniform distribution that encompasses what I think are a plausible range of early Paleogene SSTs. The uniform distribution is minimally prescriptive, allowing the data to dominate the results we get.
- Seawater $\delta^{18}$O: Here I made a reasoned guess based on my knowledge of the climate state and geochemistry at this time. The normal distribution is a little more prescriptive, implying that I have a reason to think the true value is somewhere in the vicinity of the mean.
- Transfer function parameters: These are drawn from experimental culture studies and coretop calibrations. I adopted values that were summarized in the Zachos paper. In some cases I had to use my best guess to estimate plausible ranges or standard deviations by referring to earlier work.

### Try it

**Play around with the parameters of the distributions. You can either run individual lines of code or re-compile the function and call it. Convince yourself you know what the parameters do.**

## A PSM

Now that we have a set of parameter values, let's build our PSM and run our intial values through it. The PSM here is super simple...two lines of code wrapped in a function:

```{r PSM}
#PSM calcs
psm = function(parm){
  mgca.f = parm$mgca.b * exp(parm$mgca.m * parm$sst)
  d18O.f = parm$d18O.sw - parm$sst * parm$d18O.m + parm$d18O.b
  return(list("mgca.f" = mgca.f, "d18O.f" = d18O.f))
}
```

This function, unlike `init`, takes an argument (`parm`). The argument contains information the you provide the function uses to do its calculations. In this case, the argument contains a set of six parameter values (e.g., the ones we generated using `init`). `psm` uses them to calculate the expected foraminiferal calcite Mg/Ca (`mgca.f`) and $\delta^{18}$O (`d18O.f`) values. Then it returns these values. Let's run it:

```{r runPSM}
mod = psm(parm)
mod
```

The object `parm`, which we provide here when calling the function, is the object we created above storing the model parameters generated by `init`. Here we can see the proxy values we predict for that initial condition.

### Try it

**What result do you think you would get if you provided `parm` as an argument and ran `psm` again? What if you first re-ran `init` and then ran `psm`?** 

What we have done here is very much analogous to how the data were originally interpreted in the Zachos paper. We haven't added any extra processes or fancy math, we've just posed the calculations in a forward modeling sense (rather than reverse) and developed some priors for the model parameters. 

This is really all that's required to analyze your data using Bayesian inversion. In what follows, we'll develop some code that will let us invert this model to obtain a posterior distribution for the parameters. You should know, however, that there are several well-established software packages that take care of those parts for you and are an effective solution for most problems you might tackle. The rest of our coding here is to promote learning, and isn't something you're likely to need to do routinely.

## The proposal

Now that we have a PSM and our initial conditions, the next step in MCMC is to generate a **proposal** for a new set of parameter values. To be 'Markovian', the proposal should depend on the current state of the model and a probability distribution for the jump to the next state, only. There are many strategies for generating proposals, and this is where the 'art' of MCMC (and the value of many of the software packages that conduct it) lies.

We will use a simple but effective strategy of proposing a jump for each parameter: a random variable drawn from a Gaussian distribution centered on the current value. Therefor, all we need to generate our proposal is the current set of parameter values and a standard deviation for each of the proposal distributions:

```{r prop}
#proposal
prop = function(parm){
  sst = rnorm(1, parm$sst, 0.4)
  d18O.sw = rnorm(1, parm$d18O.sw, 0.08)
  mgca.b = rnorm(1, parm$mgca.b, 0.02)
  mgca.m = rnorm(1, parm$mgca.m, 0.0012)
  d18O.b = rnorm(1, parm$d18O.b, 0.03)
  d18O.m = rnorm(1, parm$d18O.m, 0.002)
  return(list("sst" = sst, "d18O.sw" = d18O.sw,
              "mgca.b" = mgca.b, "mgca.m" = mgca.m,
              "d18O.b" = d18O.b, "d18O.m" = d18O.m))
}
```

This should start to look familiar, but feel free to ask me or your neighbor if you need help deciphering what's being done. 

How did we get the standard deviation values? The optimal values depend on the structure and nature of the model we're using, and I spent a little time tuning them to ensure the chains behave well for our problem. Again, keep in mind that MCMC software handles things like this tuning for you. In fact, it will take care of generating proposals without any coding or intervention on your part. 

Let's run our proposal function and obtain a new set of potential parameter values:

```{r runProp}
parm.n = prop(parm)
parm.n
```

The proposed values look a lot like the old ones, but each value is shifted a bit. Let's see what values they would predict for our foraminifera:

```{r propMod}
mod.n = psm(parm.n)
mod.n
```

Not identical, right? So if we have some measurements from real foraminifera we ought to be able to tell which of the sets of parameter values (`mod` or `mod.n`) is a better match with our data, right? That's next...

## Hastings ratio

The final step in MCMC involve choosing whether to accept our newly proposed parameters as part of our posterior distribution or reject them (i.e., throw them away and try again). Generally, we want to accept parameter values that are highly likely given the data that we have and our prior understanding. However, we don't want to be too rigid...we want the Markov chain to also explore the parameter space freely enough that it samples regions of intermediate and lower likelihood (ideally in proportion to their likelihood). 

Again, there are many ways of accomplishing the task, and this is where existing software shines. We will use a simple algorithm called Metropolis-Hastings. Given the properties of our model and proposal distribution, the algorithm says that we should:

- accept the proposal if the likelihood of the proposed model divided by that of the current model is greater than that of a random variable drawn from a uniform distribution bounded on (0,1), and,
- reject the proposal if not.

So in practice, we:

1. compute the likelihood of each of the models we are comparing, 
2. divide these, giving a value called the Hastings ratio,
3. draw a random value `u` between 0 and 1, and,
4. check whether the Hastings ratio is greater or less than `u`.

How do we get a model's **likelihood**? This is the joint probability of all of the parameter values given their prior distributions *and* the observed data (foraminiferal Mg/Ca and $\delta^{18}O$) given the PSM-simulated values. We calculate the probability of the observations by realizing that the PSM simulate the *expected* proxy values for the model state, but the values we actually *observe* are going to be a bit different (due to sample heterogeneity, analytical error, etc.). We thus calculate the probability density of the observed proxy values in a Gaussian distribution with a mean given by the PSM values and a standard deviation that is selected to approximate the variation we expect due to these factors. 

```{r likelihood}
like = function(mod, obs, parm){
  small = 1e-9
  #obs
  mgca.f.sd = 0.1
  d18O.f.sd = 0.15
  mgca.f.p = log(max(dnorm(obs$mgca.f, mod$mgca.f, mgca.f.sd), small))
  d18O.f.p = log(max(dnorm(obs$d18O.f, mod$d18O.f, d18O.f.sd), small))
  
  #parm
  sst.p = log(max(dunif(parm$sst, 15, 35), small))
  d18O.sw.p = log(max(dnorm(parm$d18O.sw, 0.5, 0.5), small))
  mgca.b.p = log(max(dnorm(parm$mgca.b, 0.4, 0.02), small))
  mgca.m.p = log(max(dnorm(parm$mgca.m, 0.096, 0.004), small))
  d18O.b.p = log(max(dnorm(parm$d18O.b, 2.9, 0.1), small))
  d18O.m.p = log(max(dnorm(parm$d18O.m, 0.213, 0.005), small))
  
  return(sum(c(mgca.f.p, d18O.f.p, sst.p, d18O.sw.p, mgca.b.p,
                mgca.m.p, d18O.b.p, d18O.m.p)))
}
```

Here are a few technical comments on this code for those who are into this. Feel free to skip this list if you're not interested.

1. In practice we usually work with logarithms of the probabilities to avoid truncation errors (they are often very small values). 
2. Notice we've also had to protect against zero probability values, which I do using the `max` function.
3. The summation of the log-likelihoods at the end is the equivalent of taking the product of the likelihoods, which is how we get a joint probability for independent events...things get trickier if our parameters are known to be correlated (but, again, MCMC software has support for this).

Now that we have our likelihood function, let's run it to calculate the likelihood for our two models! But, wait, first we need some data. Here are values of a late Paleocene *Morozovella* sample from the Zachos dataset:

```{r data}
obs = list("mgca.f" = 3.72, "d18O.f" = -1.42)
```

Let's get the log-likelihood for our two models and use them to compute the Hastings ratio.

```{r Hastings}
l.1 = like(mod, obs, parm)
l.2 = like(mod.n, obs, parm.n)
exp(l.2 - l.1)
```

It looks like our proposed model parameter vlaues are a little bit more likely than the old ones, and therefore might be a good set of values to include in our posterior sample. If you remember the steps in Metropolis-Hastings, we will be comparing this Hastings ratio to a random value between 0 and 1. Thus, a proposal that is more likely than the current model state will always be accepted; one that is less likely will only sometimes be accepted.

### Try it

**What was the Hastings ratio for your attempt? Try generating several new proposals and calculate Hastings ratios for them. How often to you get values greater than (or less than) 1? Given this, about what fraction of your proposals do you think would be accepted?**

## Putting it all together

OK, now that we have all the pieces we just need a function that orchestrates the steps to run the inversion and generate a Markov chain representing the posterior distribution of our model parameters. I provide such a function below. I won't go into detail (this is more stuff that MCMC software will do for you), but the comments in the code provide a guide to what each piece does.

```{r mcmc}
#run inversion
invert = function(obs, n = 1000, burnin = n/5){
  
  #space for results
  parms = data.frame("sst" = double(n), "d18O.sw" = double(n), 
                     "mgca.b" = double(n), "mgca.m" = double(n),
                     "d18O.b" = double(n), "d18O.m" = double(n))
  mods = data.frame("mgca.f" = double(n), "d18O.f" = double(n))
  
  #start with initial condition
  parm = init()
  mod = psm(parm)
  l = like(mod, obs, parm)
  
  #counters
  i = 1; ti = 1
  
  #progress bar
  pb = txtProgressBar(0, n)
  
  #iterate until we have the desired number of samples
  while(i <= n){
    #proposal
    parm.n = prop(parm)
    mod.n = psm(parm.n)
    l.n = like(mod.n, obs, parm.n)
    
    #Hastings ratio
    H = exp(l.n - l)
    
    #accept?
    if(runif(1) < H){
      #save values
      parms[i,] = (unlist(parm.n))
      mods[i,] = unlist(mod)
      
      #update current state
      parm = parm.n
      mod = mod.n
      l = l.n
      i = i + 1
      setTxtProgressBar(pb, i)
    }
    ti = ti + 1
  }
  
  #acceptance rate
  cat("\nAcceptance rate:", signif(n / ti, 2), "\n")
  
  #package results and trim the burnin period
  result = cbind(parms, mods)
  result = result[-c(1:burnin),]
  
  return(result)
}
```

With this in hand, we're finally ready to run an inversion.

```{r runMCMC}
post = invert(obs)
summary(post)
```

Cool! We have posterior distributions for all of our model parameters, including `sst` and `d18O.sw`, the two we're probably most interested in! But how do we know if they are any good? There's a lot more to learn here, but I'll show you a few simple things we can look at. First, it's really useful to look at the Markov chain itself. Here's the one we generated for `sst`:

```{r}
plot(post$sst, type = "l")
```

Here you see the 800 samples we produced by iterating through the functions we developed above. (Note: we actually generated 1000 samples, but at the end of `invert` we discarded the first 20% to avoid dependence on the initial condition, which we call **burn in**.) You see that the result truly is a 'chain'...it is an autocorrelated series of parameter values generated as the algorithm wanders through parameter space searching for values that have high likelihood. 

What we want to see here is that the chain traverses the parameter 'space' freely and repeatedly. This would suggest that it is exhaustively exploring the distribution of values and beginning to **converge** toward the true distribution. We are starting to see that here, but parts of range have only been explored once or twice, suggesting we need more samples to fill in the statistical distribution.

Another thing we can do to assess convergence is to compare multiple different (independent) chains. We'll run another one and compare the results.

```{r runMCMC2}
post2 = invert(obs)

plot(post$sst, type = "l", ylim = range(c(post$sst, post2$sst)))
lines(post2$sst, col = 2)
```

The good news here is that the two chains appear to be exploring the same general range of parameter values. But notice that the second (red) chain mainly samples higher values than the first chain. And what is going on at the beginning of the red chain? Again, this suggests that we need to let the chains run longer to converge.

Another way we can look at this is by plotting the distribution of the values the two chains have sampled:

```{r}
plot(density(post$sst))
lines(density(post2$sst), col = 2)
```

Hmm, pretty different answers. If we want a reproducible answer and would like to draw statistical conclusions from the results we want better convergence. In order to get better convergence, it looks like we'll need to run longer chains:

```{r runMCMC3}
post = invert(obs, 1e4)
post2 = invert(obs, 1e4)
```

Notice this takes a bit longer...the computation time is basically proportional to the length of the chain. Let's look at the results.

```{r plotMCMC}
plot(post$sst, type = "l")
lines(post2$sst, col = 2)
```

That's looking much better! We're now seeing that both chains are exploring the same space, and each chain has traversed its parameter space several times. 

Let's look at the posterior distributions for each chain. This time we'll also compare them with the prior distribution that we used.

```{r plotMCMC2}
x = seq(14, 36, by = 0.1)
plot(x, dunif(x, 15, 35), type = "l", ylim = c(0, 0.4), 
     ylab = "Density", xlab = "SST", col = 3)
lines(density(post$sst))
lines(density(post2$sst), col = 2)
```

Not bad! Our prior was a uniform distribution bounded between 15 and 35 degrees. After accounting for the proxy data, we end up with a nice ~Gaussian posterior indicating a mean temperature estimate of about 23.5. 

Let's look at one other important property of the posterior samples: the values of the different parameters within a given sample are not independent. Remember that when we evaluate the likelihood, we are evaluating the model state itself, i.e., the combination of the parameter values we have chosen, not each parameter individually. That means that our posterior reflects the joint probability distribution of the parameters and may reveal important covariance between parameters. Here's an example:

```{r cov}
plot(post$mgca.m, post$sst)
```

Here we are looking at the influence of the exponential parameter in the Mg/Ca - temperature relationship and the reconstructed SST, and we see that they strongly covary in the posterior. This makes sense, and shows us the influence of the model parameter on the reconstructed SST value. If `mgca.m` is on the high side, this reduces our temperature estimate, and *vice versa*. It also shows us that this parameter has a strong influence on our temperature estimates, but is not the only thing that's reflected in the variation of the SST values.

This dependence of parameter values within a given posterior sample has some important and valuable implications for how we analyze our data, which will be helpful to keep in mind below.

### Try it

**Explore the relationships between other parameters in the posterior samples. What else can you discover?**

## A paleo record

OK, now that we've set this up, let's apply it to a real paleo reconstruction. Here are our data, representing 25 depth intervals spanning the PETM. These are a slightly condensed version of the data in the supplementary information of the Zachos paper.

```{r record}
d = data.frame(
  "Depths" = c(0.890,0.940,0.990,1.040,1.090,1.140,1.190,1.200,1.210,1.220,1.230,1.240,1.250,1.260,1.270,1.280,1.290,1.300,1.31,1.32,1.33,1.34,1.39,1.44,1.48),
  "mgca.f" = c(3.919,4.092,4.242,4.158,4.309,4.708,5.401,5.406,5.517,5.523,5.571,5.282,5.592,5.369,5.267,5.419,5.224,5.188,5.151,5.176,4.989,4.732,3.706,3.618,3.724),
  "d18O.f" = c(-1.43,-1.54,-1.47,-1.67,-1.56,-1.65,-1.67,-1.72,-1.63,-1.68,-1.75,-1.76,-1.89,-1.99,-1.95,-1.93,-2.13,-1.98,-1.99,-1.93,-1.94,-1.9,-1.5,-1.43,-1.42)
  )

obs.all = list("mgca.f" = d$mgca.f, "d18O.f" = d$d18O.f)
```

In order to invert all of the data together we will need to modify our code slightly. The updated code is below. I realize it looks long and complicated, but each of the parts is directly related to and drawn from what we developed above. I won't describe the changes in detail. Feel free to just copy and run all of this to compile the functions on your computer, or look through it and see if you can identify the changes and what they do. You might also think about how this analysis is coded in terms of the examples given in lecture, and try to identify what assumptions are inherent in the approach used here.

```{r multiCode}
#initialize the chain
init.c = function(){
  mgca.b = rnorm(1, 0.4, 0.02)
  mgca.m = rnorm(1, 0.096, 0.004)
  d18O.b = rnorm(1, 2.9, 0.1)
  d18O.m = rnorm(1, 0.213, 0.005)
  
  return(list("mgca.b" = mgca.b, "mgca.m" = mgca.m,
              "d18O.b" = d18O.b, "d18O.m" = d18O.m))
}

init.v = function(){
  sst = runif(1, 28, 30)
  d18O.sw = runif(1, 0, 0.5)

  return(list("sst" = sst, "d18O.sw" = d18O.sw))
}

#proposal
prop.c = function(parm){
  mgca.b = rnorm(1, parm$mgca.b, 0.003)
  mgca.m = rnorm(1, parm$mgca.m, 0.0004)
  d18O.b = rnorm(1, parm$d18O.b, 0.02)
  d18O.m = rnorm(1, parm$d18O.m, 0.0007)
  return(list("mgca.b" = mgca.b, "mgca.m" = mgca.m,
              "d18O.b" = d18O.b, "d18O.m" = d18O.m))
}

prop.v = function(parm){
  sst = rnorm(1, parm$sst, 0.1)
  d18O.sw = rnorm(1, parm$d18O.sw, 0.02)
  return(list("sst" = sst, "d18O.sw" = d18O.sw))
}

#likelihood
like.c = function(parm){
  small = 1e-15
  #parm
  mgca.b.p = log(max(dnorm(parm$mgca.b, 0.4, 0.02), small))
  mgca.m.p = log(max(dnorm(parm$mgca.m, 0.096, 0.002), small))
  d18O.b.p = log(max(dnorm(parm$d18O.b, 2.9, 0.1), small))
  d18O.m.p = log(max(dnorm(parm$d18O.m, 0.213, 0.005), small))
  
  return(sum(c(mgca.b.p, mgca.m.p, d18O.b.p, d18O.m.p)))
}

like.v = function(mod, obs, parm){
  small = 1e-15
  #obs
  mgca.f.sd = 0.15
  d18O.f.sd = 0.15
  mgca.f.p = log(max(dnorm(obs$mgca.f, mod$mgca.f, mgca.f.sd), small))
  d18O.f.p = log(max(dnorm(obs$d18O.f, mod$d18O.f, d18O.f.sd), small))
  
  #parm
  sst.p = log(max(dunif(parm$sst, 15, 35), small))
  d18O.sw.p = log(max(dnorm(parm$d18O.sw, 0.5, 0.5), small))

  return(sum(c(mgca.f.p, d18O.f.p, sst.p, d18O.sw.p)))
}

#run inversion
invert.all = function(obs, n = 1000, burnin = n/5){
  
  #number of obs
  nobs = length(obs$mgca.f)
  
  #space for results
  parms = data.frame("mgca.b" = double(n), "mgca.m" = double(n),
                     "d18O.b" = double(n), "d18O.m" = double(n))
  sst = d18O.sw = matrix(nrow = n, ncol = nobs)

  #space for initial condition
  parm.c = parm.v = mod = parm.c.n = parm.v.n = mod.n = list()
  l.v = l.v.n = double(nobs)
  
  #get initial conditions
  parm.c = init.c()
  l.c = like.c(parm.c)
  for(j in seq(nobs)){
    parm.v[[j]] = init.v()
    mod[[j]] = psm(append(parm.v[[j]], parm.c))
    l.v[j] = like.v(mod[[j]], 
             list("mgca.f" = obs$mgca.f[j], "d18O.f" = obs$d18O.f[j]), 
             parm.v[[j]])
  }
  
  #counters
  i = 1; ti = 1
  
  #progress bar
  pb = txtProgressBar(0, n)
  
  #iterate until we have the desired number of samples
  while(i <= n){
    #fixed parms
    parm.c.n = prop.c(parm.c)
    l.c.n = like.c(parm.c.n)
    
    #cycle through all obs
    for(j in seq(nobs)){
      parm.v.n[[j]] = prop.v(parm.v[[j]])
      mod.n[[j]] = psm(append(parm.v.n[[j]], parm.c.n))
      l.v.n[j] = like.v(mod.n[[j]], 
                    list("mgca.f" = obs$mgca.f[j], "d18O.f" = obs$d18O.f[j]), 
                    parm.v.n[[j]])
    }
    
    #Hastings ratio
    H = exp(sum(c(l.c.n, l.v.n)) - sum(c(l.c, l.v)))
    
    #accept?
    if(runif(1) < H){
      #save values
      parms[i,] = unlist(parm.c.n)
      for(j in seq(nobs)){
        sst[i, j] = parm.v.n[[j]]$sst
        d18O.sw[i, j] = parm.v.n[[j]]$d18O.sw
      }

      #update current state
      parm.c = parm.c.n
      parm.v = parm.v.n
      mod = mod.n
      l.c = l.c.n
      l.v = l.v.n
      i = i + 1
      setTxtProgressBar(pb, i)
    }
    ti = ti + 1
  }
  
  #acceptance rate
  cat("\nAcceptance rate:", signif(n / ti, 2), "\n")
  
  #package results and trim the burnin period
  sst = sst[-c(1:burnin),]
  d18O.sw = d18O.sw[-c(1:burnin),]
  parms = parms[-c(1:burnin),]
  result = list("sst" = sst, "d18O.sw" = d18O.sw, "parms" = parms)

  return(result)
}
```

Once the functions are compiled we're ready to run the inversion. One important note: 

We have now increased the dimensionality of our model by a factor of ~5. The number of samples we need to get convergence (and the amount of time to obtain them) has increased commensurately. The run below took several minutes on my laptop. Depending on your computer setup ymmv. You can always start with a smaller number of posterior samples to give it a try, and then increase the number if needed.

```{r invertAll}
post = invert.all(obs.all, 1.5e5)
```

We're running out time, and I won't go through the details of examining the results and testing for convergence (feel free to do this yourself). But before we finish let's use these results to actually try to say something about PETM climate change! First, we'll plot the two environmental variables we are interested in. We'll use the medians of the posterior samples for convenience:

```{r plotAll}
par(mar = c(5, 5, 1, 5))
plot(d$Depths, apply(post$sst, 2, median), xlim = c(1.5, 0.9),
     xlab = "Depth", ylab = "SST", type = "l", lwd = 3, col = 2)
points(d$Depths, apply(post$sst, 2, median), col = 2)
par(new = TRUE)
plot(d$Depths, apply(post$d18O.sw, 2, median), 
     xlim = c(1.5, 0.9), xlab = "", ylab = "", axes = FALSE,
     type = "l", lwd = 3, col = 4)
points(d$Depths, apply(post$d18O.sw, 2, median), col = 4)
axis(4)
mtext(expression(delta^{18}*"O"["sw"]), 4, line = 3)
```

Looks pretty good! How does it compare with the results presented in the paper?

What we've done above, collapsing our results to median values, throws away most of the information we've obtained. Remember, our posterior samples represent the full, joint, multivariate distribution of all of the environmental (and PSM) parameters. What could we do with this information? A lot!

Let's just look at one example. What if we wanted to assess the SST warming during the PETM, and make statistical claims about the temperature change? For simplicity, we're going to define this as the change between the coolest value in the record (which our plot shows will generally fall just before the PETM) and the warmest (which will be somewhere around 1.25 meters core depth).

```{r warming}
warm = apply(post$sst, 2, max) - apply(post$sst, 2, min)
par(mar = c(5, 5, 1, 1))
plot(density(warm), main = "", lwd = 3, 
     xlab = expression(Delta*"(SST)"))
abline(v = median(warm))
abline(v = quantile(warm, c(0.025, 0.975)), lty = 2)
abline(v = diff(range(apply(post$sst, 2, median))), col = 2)
```

In black we have the distribution of possible warming values from our MCMC samples (plus the median and 95% credible intervals...a Bayesian version of confidence intervals). In red we have the temperature change we estimate if we first take the median SST estimate for each sample and then calculate the difference between maximum and minimum values. Why the difference? What's the better way of making this estimate? How might these results relate to assumptions we've made during our analysis? There's a lot to think about here, and I'd be happy to discuss...just lmk!

### Try it

**Explore the other parameter distributions and multivariate relationships in the posterior samples. What can you find?**

Contact me: [gabe.bowen@utah.edu](mailto:gabe.bowen@utah.edu)

More code and resources: [GitHub](https://github.com/bumbanian/USSP_JPI)
